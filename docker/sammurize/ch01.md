Instance-based learning is when a system remembers the training examples and uses them to make decisions about new data by comparing how similar they are. For example, it might label an email as spam if it looks a lot like previous spam emails. This method works well for small and changing datasets but can be slow and difficult with big or complex data.

Model-based learning is different: it builds a model from the training data that can predict new cases without having to remember every single example.

**Samurize:** There does seem to be a trend here! Although the data is noisy (i.e., partly random), it looks like life satisfaction goes up more or less linearly as the countryâ€™s GDP per capita increases. So you decide to model life satisfaction as a linear function of GDP per capita (you assume that any deviation from that line is just random noise). This step is called *model selection*: you selected a linear model of life satisfaction with just one attribute, GDP per capita (Equation 1-1).

