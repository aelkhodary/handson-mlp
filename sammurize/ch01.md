Instance-based learning is when a system remembers the training examples and uses them to make decisions about new data by comparing how similar they are. For example, it might label an email as spam if it looks a lot like previous spam emails. This method works well for small and changing datasets but can be slow and difficult with big or complex data.

Model-based learning is different: it builds a model from the training data that can predict new cases without having to remember every single example.

**Samurize:** There does seem to be a trend here! Although the data is noisy (i.e., partly random), it looks like life satisfaction goes up more or less linearly as the country’s GDP per capita increases. So you decide to model life satisfaction as a linear function of GDP per capita (you assume that any deviation from that line is just random noise). This step is called *model selection*: you selected a linear model of life satisfaction with just one attribute, GDP per capita (Equation 1-1).

**Samurize:** Sampling bias happens when the way you select your data favors certain outcomes, leading to inaccurate results. A classic case happened in the 1936 US presidential election: the Literary Digest predicted Landon would win based on a huge mail-in poll, but got it badly wrong—Roosevelt won by a landslide. Why? Their mailing lists mostly included wealthier people (from phone books, club memberships, and magazine subscribers), who were more likely to vote for Landon. That's sampling bias: their sample didn't reflect the actual US population.

On top of that, only a quarter of the people responded to the poll. Those who replied were probably more engaged or had specific views, while many ignored it. This is called nonresponse bias—a special case of sampling bias, where people who don’t answer can skew your findings.

Another example: If you want to build an AI to recognize funk music videos, and you just pull the top results for “funk music” from YouTube, you’ll mainly get popular artists—or, if you’re in Brazil, lots of “funk carioca,” which is very different from classic US funk. The search algorithm’s preferences and your location bias your training data, so your system might miss less popular or different styles of funk altogether. Sampling bias is sneaky and can sabotage your results, even if you collect tons of data!
